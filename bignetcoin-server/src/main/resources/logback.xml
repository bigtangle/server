<!-- Copyright 2018 Inasset GmbH. -->
<configuration>
	<appender name="stdout1" class="ch.qos.logback.core.ConsoleAppender">
		<encoder>
			<Pattern>"%date{yyyy-MM-dd'T'HH:mm:ss.SSSZ, Europe/Berlin}" [%thread]
				%-5level [%logger{42}:%line] - message: "%msg"%n</Pattern>
		</encoder>
	</appender>

	 <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>logs\logFile.html</file>
    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
      <!-- daily rollover -->
      <fileNamePattern>logs\logFile.%d{yyyy-MM-dd}.%i.html</fileNamePattern>
      <timeBasedFileNamingAndTriggeringPolicy
          class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
          <!-- or whenever the file size reaches 50MB -->
        <maxFileSize>50MB</maxFileSize>
      </timeBasedFileNamingAndTriggeringPolicy>
      <!-- keep 30 days' worth of history -->
      <maxHistory>30</maxHistory>
    </rollingPolicy>
    <encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
      <charset>UTF-8</charset>
      <layout class="ch.qos.logback.classic.html.HTMLLayout">
        <pattern>%d{HH:mm:ss.SSS}%thread%level%logger%line%msg</pattern>
      </layout>         
    </encoder>
  </appender> 
  
	<root level="${LOGGING_LEVEL:-INFO}">
		<appender-ref ref="stdout1" />
		<appender-ref ref="File" />
	</root>

	<logger name="net.bigtangle" level="${LOGGING_LEVEL_BIGTANGLE:-DEBUG}" />

	<logger name="org.apache.kafka" level="${LOGGING_LEVEL_KAFKA:-WARN}" />

	<logger name="org.apache.kafka.streams.KafkaStreams" level="INFO" />
	<logger name="org.apache.kafka.clients.consumer.ConsumerConfig"
		level="ERROR" />
	<logger name="org.apache.kafka.clients.producer.ProducerConfig"
		level="ERROR" />

</configuration>