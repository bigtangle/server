1) User Manuel
2) Deploy for test
3) Kafka Streaming and relay, spam protect 
4) mining reward
5) UI display for address blocks and filters
6) Hbase with Phoenix
7) Cassandra
8) validation of different blocks
9) add market as option, enable the strict caution
10) enable stop mutiple token issance 



## 


data in transaction:
	Structure data into transaction for transfer, see Email PGP
	transfer encrpyte ddata into tangle with  owner private key.
	It must remove the usage of public key hash, but public key.
	
Shareable data enable to add my post address:
  Structure data post address as json into data   
  data is secured by encrypted with AES by private key
   transfer my data to other:  signed the data by other public key
   post address + public encrypted
   
  	  
Wait to use spark X
merge  tables headers and blockevaluation into single table blocks, avoid join for milestone  ?





11) Spark implementation of milestone:

1) load the init data for Hbase
2) build the graph 
3) evaluation of milestone
4) time refresh
5) read the new data from hbase or read it from kafka stream
6) milestone update and write evaluation data into hbase


12) move the block-> tokenid to transaction out
13) refactoring 